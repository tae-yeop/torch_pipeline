{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from diffusers import StableDiffusion3Pipeline\n",
    "import debugpy\n",
    "\n",
    "# debugpy.listen(('0.0.0.0', 5678))\n",
    "\n",
    "# print(\"Waiting for debugger attach\")\n",
    "# debugpy.wait_for_client()\n",
    "\n",
    "# pipe = StableDiffusion3Pipeline.from_pretrained(\"stabilityai/stable-diffusion-3-medium-diffusers\", torch_dtype=torch.float16, cache_dir='/purestorage/project/tyk/tmp')\n",
    "# pipe = pipe.to(\"cuda\")\n",
    "# print(pipe.diffuers.config)\n",
    "\n",
    "\n",
    "def get_timestep_embedding(\n",
    "    timesteps: torch.Tensor,\n",
    "    embedding_dim: int,\n",
    "    flip_sin_to_cos: bool = False,\n",
    "    downscale_freq_shift: float = 1,\n",
    "    scale: float = 1,\n",
    "    max_period: int = 10000,\n",
    "):\n",
    "    \"\"\"\n",
    "    This matches the implementation in Denoising Diffusion Probabilistic Models: Create sinusoidal timestep embeddings.\n",
    "\n",
    "    Args\n",
    "        timesteps (torch.Tensor):\n",
    "            a 1-D Tensor of N indices, one per batch element. These may be fractional.\n",
    "        embedding_dim (int):\n",
    "            the dimension of the output.\n",
    "        flip_sin_to_cos (bool):\n",
    "            Whether the embedding order should be `cos, sin` (if True) or `sin, cos` (if False)\n",
    "        downscale_freq_shift (float):\n",
    "            Controls the delta between frequencies between dimensions\n",
    "        scale (float):\n",
    "            Scaling factor applied to the embeddings.\n",
    "        max_period (int):\n",
    "            Controls the maximum frequency of the embeddings\n",
    "    Returns\n",
    "        torch.Tensor: an [N x dim] Tensor of positional embeddings.\n",
    "    \"\"\"\n",
    "    assert len(timesteps.shape) == 1, \"Timesteps should be a 1d-array\"\n",
    "\n",
    "    half_dim = embedding_dim // 2\n",
    "    exponent = -math.log(max_period) * torch.arange(\n",
    "        start=0, end=half_dim, dtype=torch.float32, device=timesteps.device\n",
    "    )\n",
    "    exponent = exponent / (half_dim - downscale_freq_shift)\n",
    "\n",
    "    emb = torch.exp(exponent)\n",
    "    emb = timesteps[:, None].float() * emb[None, :]\n",
    "\n",
    "    # scale embeddings\n",
    "    emb = scale * emb\n",
    "\n",
    "    # concat sine and cosine embeddings\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "\n",
    "    # flip sine and cosine embeddings\n",
    "    if flip_sin_to_cos:\n",
    "        emb = torch.cat([emb[:, half_dim:], emb[:, :half_dim]], dim=-1)\n",
    "\n",
    "    # zero pad\n",
    "    if embedding_dim % 2 == 1:\n",
    "        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n",
    "    return emb\n",
    "\n",
    "\n",
    "# Example usage\n",
    "timesteps = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=torch.float32)\n",
    "embedding_dim = 8\n",
    "\n",
    "embeddings = get_timestep_embedding(\n",
    "    timesteps,\n",
    "    embedding_dim,\n",
    "    flip_sin_to_cos=False,\n",
    "    downscale_freq_shift=1,\n",
    "    scale=1.0,\n",
    "    max_period=10000\n",
    ")\n",
    "\n",
    "# Convert embeddings to numpy for plotting\n",
    "embeddings_np = embeddings.detach().cpu().numpy()\n",
    "\n",
    "# Plot the embeddings\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(embedding_dim):\n",
    "    plt.plot(timesteps.numpy(), embeddings_np[:, i], label=f'Dimension {i+1}')\n",
    "plt.title('Timestep Embeddings')\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ylabel('Embedding Value')\n",
    "plt.legend()\n",
    "plt.savefig('timestep_embeddings.png')  # Save the figure as a PNG file\n",
    "plt.close()\n",
    "\n",
    "print(\"The timestep embeddings plot has been saved as 'timestep_embeddings.png'.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
