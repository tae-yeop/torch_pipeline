{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f26444c6b50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CausalConv1d\n",
    "\n",
    "- 시계열, Autoregressive model에 사용\n",
    "- 왼쪽(과거)에 패딩, 오른쪽(미래)에는 패딩 없이\n",
    "- 1D Conv이므로 weight.shape = (32, 16, 3)  [in_channels=16, out_channels=32, kernel_size=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1d(nn.Conv1d):\n",
    "    \"\"\"\n",
    "    홀수 커널\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # 왼쪽 부분 얼만큼 패딩 줄지\n",
    "        self.causal_padding = self.dilation[0] * (self.kernel_size[0] - 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 왼쪽으로 self.causal_padding만큼 0-padding\n",
    "        # 오른쪽 패딩은 주지 않음([self.causal_padding, 0])\n",
    "        return self._conv_forward(\n",
    "            F.pad(x, [self.causal_padding, 0]), self.weight, self.bias\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 1, 8])\n",
      "Input tensor: tensor([[[0., 1., 2., 3., 4., 5., 6., 7.]]])\n",
      "Output shape: torch.Size([1, 1, 8])\n",
      "Output tensor: tensor([[[ 0.0000, -0.4752, -0.9504, -1.1158, -1.2813, -1.4511, -1.6209,\n",
      "          -1.7907]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(8, dtype=torch.float32).reshape(1, 1, -1)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Input tensor:\", x)\n",
    "\n",
    "causal_conv = CausalConv1d(in_channels=1, out_channels=1,\n",
    "                           kernel_size=3, dilation=2, bias=False)\n",
    "\n",
    "y = causal_conv(x)\n",
    "\n",
    "print(\"Output shape:\", y.shape)\n",
    "print(\"Output tensor:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 짝수 커널 처리 함수형\n",
    "def causal_padding(x, kernel):\n",
    "    if kernel.shape[-1] % 2 == 0:\n",
    "        kernel = F.pad(kernel, [1,0], value=0.0)\n",
    "\n",
    "    x = F.pad(x, [kernel.shape[-1]-1, 0], value=0.0)\n",
    "    return x, kernel\n",
    "\n",
    "\n",
    "def causal_conv(x, kernel, bias=None, **kwargs):\n",
    "    x, kernel = causal_padding(x, kernel)\n",
    "    return F.conv1d(x, kernel, bias=bias, padding=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1d(nn.Conv1d):\n",
    "    \"\"\"\n",
    "    짝수 커널도 처리\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # (1) weight를 가져옴\n",
    "        weight = self.weight  # shape: (out_ch, in_ch, K)\n",
    "\n",
    "        # (2) 커널 길이가 짝수라면 왼쪽 1칸을 pad해\n",
    "        #     실제 연산 시에는 \"홀수 커널\"이 되도록 만듦\n",
    "        # 예: kernel_size=4 → shape=(out_ch, in_ch, 5)\n",
    "        if weight.shape[-1] % 2 == 0:\n",
    "            weight = F.pad(weight, [1, 0], value=0.0)\n",
    "\n",
    "        # (3) 최종 커널 크기(홀수)\n",
    "        kernel_size = weight.shape[-1]\n",
    "\n",
    "        # (4) 인과적 패딩(왼쪽) 계산: dilation*(kernel_size - 1)\n",
    "        #     → 미래 정보가 들어오지 않도록 왼쪽만 패딩\n",
    "        causal_padding = self.dilation[0] * (kernel_size - 1)\n",
    "\n",
    "        # (5) 입력 x에 왼쪽만 0-패딩\n",
    "        x = F.pad(x, [causal_padding, 0], value=0.0)\n",
    "\n",
    "        # (6) conv1d 수행 (padding=0)\n",
    "        return F.conv1d(x, weight, self.bias,\n",
    "                         self.stride, 0,\n",
    "                         self.dilation, self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (배치=1, 채널=1, 길이=10) 형태의 입력을 생성 (0~9 범위)\n",
    "x = torch.arange(10, dtype=torch.float32).reshape(1, 1, -1)\n",
    "print(\"Input x shape:\", x.shape)\n",
    "print(\"Input x:\", x)\n",
    "\n",
    "# 커널 사이즈=4(짝수)로 설정 → forward에서 자동으로 한 칸 pad하여 홀수화\n",
    "causal_conv = CausalConv1d(in_channels=1, out_channels=1, kernel_size=4, bias=False)\n",
    "\n",
    "# Forward\n",
    "y = causal_conv(x)\n",
    "print(\"Output y shape:\", y.shape)\n",
    "print(\"Output y:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CausalConvTranspose1d\n",
    "- ConvTranspose인데 causal 버전\n",
    "- 미래 시점을 보지 않도록 함\n",
    "- 디코딩, 업샘플에서 causal conv에 반대되는 개념으로 쓸 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConvTranspose1d(nn.ConvTranspose1d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # 뒤쪽(미래)을 일정 길이만큼 제거\n",
    "        self.causal_padding = (\n",
    "            self.dilation[0] * (self.kernel_size[0] - 1)\n",
    "            + self.output_padding[0]\n",
    "            + 1\n",
    "            - self.stride[0]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, output_size=None):\n",
    "        if self.padding_mode != 'zeros':\n",
    "            raise ValueError('Only `zeros` padding mode is supported for ConvTranspose1d')\n",
    "\n",
    "        assert isinstance(self.padding, tuple)\n",
    "        output_padding = self._output_padding(\n",
    "            x, output_size, self.stride, self.padding, self.kernel_size, self.dilation)\n",
    "\n",
    "        # 실제 Transposed Conv 진행\n",
    "        out = F.conv_transpose1d(\n",
    "            x, self.weight, self.bias, self.stride, self.padding,\n",
    "            output_padding, self.groups, self.dilation\n",
    "        )\n",
    "        # 인과적 구조를 위해 끝부분(미래) 잘라내기\n",
    "        return out[..., :-self.causal_padding]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Conv Encoder+Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation):\n",
    "        super().__init__()\n",
    "        self.dilation = dilation\n",
    "        self.layers = nn.Sequential(\n",
    "            CausalConv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=7,\n",
    "                dilation=dilation\n",
    "            ),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, out_channels, stride):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            CausalConvTranspose1d(\n",
    "                in_channels=2*out_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=2*stride, \n",
    "                stride=stride\n",
    "            ),\n",
    "            nn.ELU(),\n",
    "            ResBlock(\n",
    "                in_channels=out_channels, \n",
    "                out_channels=out_channels,\n",
    "                dilation=1\n",
    "            ),\n",
    "            nn.ELU(),\n",
    "            ResBlock(\n",
    "                in_channels=out_channels, \n",
    "                out_channels=out_channels,\n",
    "                dilation=3\n",
    "            ),\n",
    "            nn.ELU(),\n",
    "            ResBlock(in_channels=out_channels, out_channels=out_channels,\n",
    "                         dilation=9),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted separable convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SepConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Inverted separable convolution from MobileNetV2: https://arxiv.org/abs/1801.04381.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, expansion_ratio=2, act1_layer=StarReLU, act2_layer=nn.Identity,\n",
    "                 bias=False, kernel_size=7, padding=3, **kwargs,):\n",
    "        super().__init__()\n",
    "        med_channels = int(expansion_ratio * dim)\n",
    "        self.pwconv1 = nn.Linear(dim, med_channels, bias=bias)\n",
    "        self.act1 = act1_layer()\n",
    "        self.dwconv = nn.Conv2d(\n",
    "            med_channels, med_channels, kernel_size=kernel_size,\n",
    "            padding=padding, groups=med_channels, bias=bias\n",
    "        )\n",
    "        self.act2 = act2_layer()\n",
    "        self.pwconv2 = nn.Linear(med_channels, dim, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act1(x)\n",
    "        # [B, H, W, C] => [B, C, H, W]\n",
    "        x = x.permute(0, 3, 2, 1)\n",
    "        x = self.dwconv(x)\n",
    "        # [B, C, H, W] => [B, H, W, C]\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.act2(x)\n",
    "        x = self.pwconv2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'domain_rgb': 1, 'l1_lambda': 2, 'l2_lambda': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleLoss(\n",
       "  (l1_loss): L1Loss()\n",
       "  (l2_loss): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "def my_decorator(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "\n",
    "        # args와 kwargs에서 파라미터 이름을 얻기 위해 사용\n",
    "        param_names = func.__code__.co_varnames[1:func.__code__.co_argcount]\n",
    "        params = dict(zip(param_names, args))  # 위치인자 처리\n",
    "        print(params)\n",
    "        params.update(kwargs)  # 키워드 인자 업데이트\n",
    "\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "        func(self, *args, **kwargs)  # 먼저 원래의 초기화 함수를 실행합니다.\n",
    "    return wrapper\n",
    "\n",
    "class SimpleLoss(nn.Module):\n",
    "    @my_decorator\n",
    "    def __init__(self, domain_rgb, l1_lambda, l2_lambda):\n",
    "        super().__init__()\n",
    "        # 추가적인 초기화 코드가 여기에 포함될 수 있습니다.\n",
    "        self.l1_loss = nn.L1Loss() if self.l1_lambda != 0 else None\n",
    "        self.l2_loss = nn.MSELoss() if self.l2_lambda != 0 else None\n",
    "\n",
    "# 테스트\n",
    "SimpleLoss(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
