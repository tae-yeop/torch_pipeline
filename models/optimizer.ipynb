{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import inspect\n",
    "\n",
    "try:\n",
    "    import bitsandbytes as bnb\n",
    "    adam8bit_class = bnb.optim.Adam8bit\n",
    "except ImportError:\n",
    "    adam8bit_class = None\n",
    "    # pass, raise ImportError\n",
    "\n",
    "try:\n",
    "    import prodigyopt\n",
    "    prodigy_class = prodigyopt.Prodigy\n",
    "except ImportError:\n",
    "    prodigy_class = None\n",
    "\n",
    "optimizer_dict = {'adam': torch.optim.Adam, 'adam8bit': adam8bit_class, 'adamw': torch.optim.AdamW, 'prodigy': prodigy_class}\n",
    "\n",
    "def filter_valid_params(constructor, params_dict):\n",
    "    valid_params = inspect.signature(constructor).parameters\n",
    "    filtered_params = {key: value for key, value in params_dict.items() if key in valid_params}\n",
    "    return filtered_params\n",
    "\n",
    "def prepare_optimizer_params(models, learning_rates):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model1 = torch.nn.Linear(3,4)\n",
    "model2 = torch.nn.Conv2d(3, 6)\n",
    "# 메모리 줄이기\n",
    "model1_parameters = list(filter(lambda p: p.requires_grad, model1.parameters()))\n",
    "model1_parameters_with_lr = {\"params\": model1_parameters, \"lr\": 0.15}\n",
    "\n",
    "model2_parameters = list(filter(lambda p: p.requires_grad, model2.parameters()))\n",
    "model2_parameters_with_lr = {\"params\": model2_parameters, \"lr\": 0.1}\n",
    "\n",
    "\n",
    "params_to_optimizer = [model1_parameters_with_lr, model2_parameters_with_lr]\n",
    "my_params = {'betas' : (0.1, 0.1), 'weight_decay' : 0.99, 'eps':0.999, 'lr': 0.01}\n",
    "for key, optimizer_class in optimizer_dict.items():\n",
    "    if optimizer_class is None:\n",
    "        continue\n",
    "    if key == 'adam8bit':\n",
    "        \n",
    "        my_params['lr'] = 0.15\n",
    "    valid_params = filter_valid_params(optimizer_class, my_params)\n",
    "    print(valid_params)\n",
    "    optimizer = optimizer_class(params_to_optimize, **valid_params)\n",
    "    print(optimizer)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
