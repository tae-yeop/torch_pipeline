{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def g_logistic_loss(fake_pred):\n",
    "    return F.softplus(-fake_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def d_logistic_loss(real_pred, fake_pred):\n",
    "    real_loss = F.softplus(-real_pred)\n",
    "    fake_loss = F.softplus(fake_pred)\n",
    "    return real_loss.mean() + fake_loss.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def g_hinge(d_logit_fake):\n",
    "    return -torch.mean(d_logit_fake)\n",
    "\n",
    "def d_hinge(d_logit_real, d_logit_fake):\n",
    "    return torch.mean(F.relu(1. - d_logit_real)) + torch.mean(F.relu(1. + d_logit_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def d_r1_loss(real_logit, real_img, r1_gamma):\n",
    "    grad_real, = grad(outputs=real_logit.sum(), inputs=real_img, create_graph=True)\n",
    "    grad_penalty = grad_real.pow(2).reshape(grad_real.shape[0], -1).sum(1).mean()\n",
    "    return 0.5 * r1_gamma * grad_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Quality Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def tv_loss(img):\n",
    "    # https://github.com/chongyangma/cs231n/blob/master/assignments/assignment3/style_transfer_pytorch.py\n",
    "    # https://github.com/Lightning-AI/torchmetrics/blob/master/src/torchmetrics/functional/image/tv.py\n",
    "    w_variance = torch.sum(torch.pow(img[:,:,:,:-1] - img[:,:,:,1:], 2))\n",
    "    h_variance = torch.sum(torch.pow(img[:,:,:-1,:] - img[:,:,1:,:], 2))\n",
    "    loss = (h_variance + w_variance)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def _fspecial_gauss_1d(size: int, sigma: float) -> Tensor:\n",
    "    r\"\"\"Create 1-D gauss kernel\n",
    "    Args:\n",
    "        size (int): the size of gauss kernel\n",
    "        sigma (float): sigma of normal distribution\n",
    "    Returns:\n",
    "        torch.Tensor: 1D kernel (1 x 1 x size)\n",
    "    \"\"\"\n",
    "    coords = torch.arange(size, dtype=torch.float)\n",
    "    coords -= size // 2\n",
    "\n",
    "    g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))\n",
    "    g /= g.sum()\n",
    "\n",
    "    return g.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "def gaussian_filter(input: Tensor, win: Tensor) -> Tensor:\n",
    "    r\"\"\" Blur input with 1-D kernel\n",
    "    Args:\n",
    "        input (torch.Tensor): a batch of tensors to be blurred\n",
    "        window (torch.Tensor): 1-D gauss kernel\n",
    "    Returns:\n",
    "        torch.Tensor: blurred tensors\n",
    "    \"\"\"\n",
    "    assert all([ws == 1 for ws in win.shape[1:-1]]), win.shape\n",
    "    if len(input.shape) == 4:\n",
    "        conv = F.conv2d\n",
    "    elif len(input.shape) == 5:\n",
    "        conv = F.conv3d\n",
    "    else:\n",
    "        raise NotImplementedError(input.shape)\n",
    "\n",
    "    C = input.shape[1]\n",
    "    out = input\n",
    "    for i, s in enumerate(input.shape[2:]):\n",
    "        if s >= win.shape[-1]:\n",
    "            out = conv(out, weight=win.transpose(2 + i, -1), stride=1, padding=0, groups=C)\n",
    "        else:\n",
    "            warnings.warn(\n",
    "                f\"Skipping Gaussian Smoothing at dimension 2+{i} for input: {input.shape} and win size: {win.shape[-1]}\"\n",
    "            )\n",
    "\n",
    "    return out\n",
    "\n",
    "def _ssim(\n",
    "    X: Tensor,\n",
    "    Y: Tensor,\n",
    "    data_range: float,\n",
    "    win: Tensor,\n",
    "    size_average: bool = True,\n",
    "    K: Union[Tuple[float, float], List[float]] = (0.01, 0.03)\n",
    ") -> Tuple[Tensor, Tensor]:\n",
    "    r\"\"\" Calculate ssim index for X and Y\n",
    "\n",
    "    Args:\n",
    "        X (torch.Tensor): images\n",
    "        Y (torch.Tensor): images\n",
    "        data_range (float or int): value range of input images. (usually 1.0 or 255)\n",
    "        win (torch.Tensor): 1-D gauss kernel\n",
    "        size_average (bool, optional): if size_average=True, ssim of all images will be averaged as a scalar\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: ssim results.\n",
    "    \"\"\"\n",
    "    K1, K2 = K\n",
    "    # batch, channel, [depth,] height, width = X.shape\n",
    "    compensation = 1.0\n",
    "\n",
    "    C1 = (K1 * data_range) ** 2\n",
    "    C2 = (K2 * data_range) ** 2\n",
    "\n",
    "    win = win.to(X.device, dtype=X.dtype)\n",
    "\n",
    "    mu1 = gaussian_filter(X, win)\n",
    "    mu2 = gaussian_filter(Y, win)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = compensation * (gaussian_filter(X * X, win) - mu1_sq)\n",
    "    sigma2_sq = compensation * (gaussian_filter(Y * Y, win) - mu2_sq)\n",
    "    sigma12 = compensation * (gaussian_filter(X * Y, win) - mu1_mu2)\n",
    "\n",
    "    cs_map = (2 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)  # set alpha=beta=gamma=1\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) / (mu1_sq + mu2_sq + C1)) * cs_map\n",
    "\n",
    "    ssim_per_channel = torch.flatten(ssim_map, 2).mean(-1)\n",
    "    cs = torch.flatten(cs_map, 2).mean(-1)\n",
    "    return ssim_per_channel, cs\n",
    "\n",
    "def ssim(\n",
    "    X: Tensor,\n",
    "    Y: Tensor,\n",
    "    data_range: float = 255,\n",
    "    size_average: bool = True,\n",
    "    win_size: int = 11,\n",
    "    win_sigma: float = 1.5,\n",
    "    win: Optional[Tensor] = None,\n",
    "    K: Union[Tuple[float, float], List[float]] = (0.01, 0.03),\n",
    "    nonnegative_ssim: bool = False,\n",
    ") -> Tensor:\n",
    "    r\"\"\" interface of ssim\n",
    "    Args:\n",
    "        X (torch.Tensor): a batch of images, (N,C,H,W)\n",
    "        Y (torch.Tensor): a batch of images, (N,C,H,W)\n",
    "        data_range (float or int, optional): value range of input images. (usually 1.0 or 255)\n",
    "        size_average (bool, optional): if size_average=True, ssim of all images will be averaged as a scalar\n",
    "        win_size: (int, optional): the size of gauss kernel\n",
    "        win_sigma: (float, optional): sigma of normal distribution\n",
    "        win (torch.Tensor, optional): 1-D gauss kernel. if None, a new kernel will be created according to win_size and win_sigma\n",
    "        K (list or tuple, optional): scalar constants (K1, K2). Try a larger K2 constant (e.g. 0.4) if you get a negative or NaN results.\n",
    "        nonnegative_ssim (bool, optional): force the ssim response to be nonnegative with relu\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: ssim results\n",
    "    \"\"\"\n",
    "    if not X.shape == Y.shape:\n",
    "        raise ValueError(f\"Input images should have the same dimensions, but got {X.shape} and {Y.shape}.\")\n",
    "\n",
    "    for d in range(len(X.shape) - 1, 1, -1):\n",
    "        X = X.squeeze(dim=d)\n",
    "        Y = Y.squeeze(dim=d)\n",
    "\n",
    "    if len(X.shape) not in (4, 5):\n",
    "        raise ValueError(f\"Input images should be 4-d or 5-d tensors, but got {X.shape}\")\n",
    "\n",
    "    #if not X.type() == Y.type():\n",
    "    #    raise ValueError(f\"Input images should have the same dtype, but got {X.type()} and {Y.type()}.\")\n",
    "\n",
    "    if win is not None:  # set win_size\n",
    "        win_size = win.shape[-1]\n",
    "\n",
    "    if not (win_size % 2 == 1):\n",
    "        raise ValueError(\"Window size should be odd.\")\n",
    "\n",
    "    if win is None:\n",
    "        win = _fspecial_gauss_1d(win_size, win_sigma)\n",
    "        win = win.repeat([X.shape[1]] + [1] * (len(X.shape) - 1))\n",
    "\n",
    "    ssim_per_channel, cs = _ssim(X, Y, data_range=data_range, win=win, size_average=False, K=K)\n",
    "    if nonnegative_ssim:\n",
    "        ssim_per_channel = torch.relu(ssim_per_channel)\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_per_channel.mean()\n",
    "    else:\n",
    "        return ssim_per_channel.mean(1)\n",
    "\n",
    "\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_range: float = 255,\n",
    "        size_average: bool = True,\n",
    "        win_size: int = 11,\n",
    "        win_sigma: float = 1.5,\n",
    "        channel: int = 3,\n",
    "        spatial_dims: int = 2,\n",
    "        K: Union[Tuple[float, float], List[float]] = (0.01, 0.03),\n",
    "        nonnegative_ssim: bool = False,\n",
    "    ) -> None:\n",
    "        r\"\"\" class for ssim\n",
    "        Args:\n",
    "            data_range (float or int, optional): value range of input images. (usually 1.0 or 255)\n",
    "            size_average (bool, optional): if size_average=True, ssim of all images will be averaged as a scalar\n",
    "            win_size: (int, optional): the size of gauss kernel\n",
    "            win_sigma: (float, optional): sigma of normal distribution\n",
    "            channel (int, optional): input channels (default: 3)\n",
    "            K (list or tuple, optional): scalar constants (K1, K2). Try a larger K2 constant (e.g. 0.4) if you get a negative or NaN results.\n",
    "            nonnegative_ssim (bool, optional): force the ssim response to be nonnegative with relu.\n",
    "        \"\"\"\n",
    "\n",
    "        super(SSIM, self).__init__()\n",
    "        self.win_size = win_size\n",
    "        self.win = _fspecial_gauss_1d(win_size, win_sigma).repeat([channel, 1] + [1] * spatial_dims)\n",
    "        self.size_average = size_average\n",
    "        self.data_range = data_range\n",
    "        self.K = K\n",
    "        self.nonnegative_ssim = nonnegative_ssim\n",
    "\n",
    "    def forward(self, X: Tensor, Y: Tensor) -> Tensor:\n",
    "        return ssim(\n",
    "            X,\n",
    "            Y,\n",
    "            data_range=self.data_range,\n",
    "            size_average=self.size_average,\n",
    "            win=self.win,\n",
    "            K=self.K,\n",
    "            nonnegative_ssim=self.nonnegative_ssim,\n",
    "        )\n",
    "\n",
    "\n",
    "class SSIM_Loss(SSIM):\n",
    "    def forward(self, img1, img2):\n",
    "        return ( 1 - super(SSIM_Loss, self).forward(img1, img2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class IDLoss(nn.Module):\n",
    "    # sh ./download_from_google_drive.sh 1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn model_ir_se50.pth\n",
    "    def __init__(self, backbone_path):\n",
    "        super(IDLoss, self).__init__()\n",
    "        print('Loading ResNet ArcFace')\n",
    "        self.facenet = Backbone(input_size=112, num_layers=50, drop_ratio=0.6, mode='ir_se')\n",
    "        try:\n",
    "            self.facenet.load_state_dict(load_state_dict(backbone_path, location='cpu'))\n",
    "        except IOError:\n",
    "            self.facenet.load_state_dict(torch.load('/apdcephfs/share_916081/amosyhliu/pretrained_models/model_ir_se50.pth'))\n",
    "\n",
    "        self.face_pool = torch.nn.AdaptiveAvgPool2d((112, 112))\n",
    "        self.facenet.eval()\n",
    "\n",
    "    def extract_feats(self, x):\n",
    "        x = x[:, :, 35:223, 32:220]  # Crop interesting region\n",
    "        x = self.face_pool(x)\n",
    "        x_feats = self.facenet(x)\n",
    "        return x_feats\n",
    "\n",
    "    def forward(self, x, x_hat):\n",
    "        self.facenet.eval()\n",
    "        n_samples = x.shape[0]\n",
    "        x_feats = self.extract_feats(x)\n",
    "        x_feats = x_feats.detach()\n",
    "\n",
    "        x_hat_feats = self.extract_feats(x_hat)\n",
    "        losses = []\n",
    "        for i in range(n_samples):\n",
    "            loss_sample = 1 - x_hat_feats[i].dot(x_feats[i])\n",
    "            losses.append(loss_sample.unsqueeze(0))\n",
    "\n",
    "        losses = torch.cat(losses, dim=0)\n",
    "        return losses / n_samples\n",
    "\n",
    "\n",
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, pred, tgt, m):\n",
    "        return self.mse(m*pred, m*tgt)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
