{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "means = [0.485, 0.456, 0.406]\n",
    "stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "t_stds = torch.tensor(stds).cuda().half()[:,None,None]\n",
    "t_means = torch.tensor(means).cuda().half()[:,None,None]\n",
    "\n",
    "img_transforms = transforms.Compose([                        \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(means,stds)])\n",
    " \n",
    "def tensor2im(var):\n",
    "     return var.mul(t_stds).add(t_means).mul(255.).clamp(0,255).permute(1,2,0)\n",
    "\n",
    "def proc_pil_img(input_image, model):\n",
    "    transformed_image = img_transforms(input_image)[None,...].cuda().half()\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        result_image = model(transformed_image)[0]; print(result_image.shape)\n",
    "        output_image = tensor2im(result_image)\n",
    "        output_image = output_image.detach().cpu().numpy().astype('uint8')\n",
    "        output_image = PIL.Image.fromarray(output_image)\n",
    "    return output_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def process(src_path, dest_path):\n",
    "  in_files = sorted(glob(f'{src_path}/*'))\n",
    "  for img in tqdm(in_files):\n",
    "    out = f\"{dest_path}/{img.split('/')[-1].split('.')[0]}.jpg\"\n",
    "    im = PIL.Image.open(img).resize((512, 512)).convert(\"RGB\") \n",
    "    im = scale_by_face_size(im, target_face=300, max_res=1_500_000, max_upscale=1)\n",
    "    res = proc_pil_img(im, model)\n",
    "    res.save(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 텐서를 이미지로\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "def tensor2im(x) -> Image.Image:\n",
    "    return Image.fromarray(x.cpu().numpy().astype(np.uint8) * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 이미지 다운\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "ip_adapter_image = download_image(\"https://cdn-uploads.huggingface.co/production/uploads/1668693456211-noauth.jpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# PIL 이미지를 그리드로 저장\n",
    "def image_grid(imgs:PIL.Image, rows:int, cols:int):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
