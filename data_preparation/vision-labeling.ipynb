{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grounded-Segment-Anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"GroundingDINO\"))\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from torchvision.ops import box_convert\n",
    "\n",
    "# Grounding DINO\n",
    "import GroundingDINO.groundingdino.datasets.transforms as T\n",
    "from GroundingDINO.groundingdino.models import build_model\n",
    "from GroundingDINO.groundingdino.util import box_ops\n",
    "from GroundingDINO.groundingdino.util.slconfig import SLConfig\n",
    "from GroundingDINO.groundingdino.util.utils import clean_state_dict, get_phrases_from_posmap\n",
    "from GroundingDINO.groundingdino.util.inference import annotate, load_image, predict\n",
    "\n",
    "import supervision as sv\n",
    "\n",
    "# segment anything\n",
    "from segment_anything import build_sam, SamPredictor \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# diffusers\n",
    "import PIL\n",
    "import requests\n",
    "import torch\n",
    "from io import BytesIO\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "def load_model_hf(repo_id, filename, ckpt_config_filename, device='cpu'):\n",
    "    cache_config_file = hf_hub_download(repo_id=repo_id, filename=ckpt_config_filename)\n",
    "\n",
    "    args = SLConfig.fromfile(cache_config_file) \n",
    "    model = build_model(args)\n",
    "    args.device = device\n",
    "\n",
    "    cache_file = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "    checkpoint = torch.load(cache_file, map_location='cpu')\n",
    "    log = model.load_state_dict(clean_state_dict(checkpoint['model']), strict=False)\n",
    "    print(\"Model loaded from {} \\n => {}\".format(cache_file, log))\n",
    "    _ = model.eval()\n",
    "    return model   \n",
    "\n",
    "ckpt_repo_id = \"ShilongLiu/GroundingDINO\"\n",
    "ckpt_filenmae = \"groundingdino_swinb_cogcoor.pth\"\n",
    "ckpt_config_filename = \"GroundingDINO_SwinB.cfg.py\"\n",
    "\n",
    "groundingdino_model = load_model_hf(ckpt_repo_id, ckpt_filenmae, ckpt_config_filename)\n",
    "\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "sam_checkpoint = 'sam_vit_h_4b8939.pth'\n",
    "sam = build_sam(checkpoint=sam_checkpoint)\n",
    "sam.to(device=DEVICE)\n",
    "sam_predictor = SamPredictor(sam)\n",
    "\n",
    "\n",
    "\n",
    "def do_inference(prompt=\"dog\", box_threshold=0.3, text_threshold=0.25, local_image_path='assets/animals/강아지1.jpeg', out_path='out.png'):\n",
    "    image_source, image = load_image(local_image_path)\n",
    "    boxes, logits, phrases = predict(\n",
    "        model=groundingdino_model, \n",
    "        image=image, \n",
    "        caption=prompt, \n",
    "        box_threshold=box_threshold, \n",
    "        text_threshold=text_threshold,\n",
    "        device=DEVICE\n",
    "    )\n",
    "\n",
    "    annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "    annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "    # Image.fromarray(annotated_frame).save('detection.png')\n",
    "\n",
    "\n",
    "    sam_predictor.set_image(image_source)\n",
    "\n",
    "\n",
    "    H, W, _ = image_source.shape\n",
    "    boxes_xyxy = box_ops.box_cxcywh_to_xyxy(boxes) * torch.Tensor([W, H, W, H])\n",
    "\n",
    "\n",
    "    transformed_boxes = sam_predictor.transform.apply_boxes_torch(boxes_xyxy, image_source.shape[:2]).to(DEVICE)\n",
    "    masks, _, _ = sam_predictor.predict_torch(\n",
    "                point_coords = None,\n",
    "                point_labels = None,\n",
    "                boxes = transformed_boxes,\n",
    "                multimask_output = False,\n",
    "            )\n",
    "\n",
    "\n",
    "    def show_mask(mask, image, random_color=True):\n",
    "        if random_color:\n",
    "            color = np.concatenate([np.random.random(3), np.array([0.8])], axis=0)\n",
    "        else:\n",
    "            color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "        h, w = mask.shape[-2:]\n",
    "        mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "        \n",
    "        annotated_frame_pil = Image.fromarray(image).convert(\"RGBA\")\n",
    "        mask_image_pil = Image.fromarray((mask_image.cpu().numpy() * 255).astype(np.uint8)).convert(\"RGBA\")\n",
    "\n",
    "        return np.array(Image.alpha_composite(annotated_frame_pil, mask_image_pil))\n",
    "\n",
    "    annotated_frame_with_mask = show_mask(masks[0][0].cpu(), annotated_frame)\n",
    "\n",
    "    Image.fromarray(annotated_frame_with_mask).save('test.png')\n",
    "\n",
    "    image_mask = masks[0][0].cpu().numpy()\n",
    "    image_mask_pil = Image.fromarray(image_mask).convert(\"L\")\n",
    "    image_source_pil = Image.fromarray(image_source)\n",
    "\n",
    "    result_image = Image.composite(image_source_pil, Image.new(\"RGB\", image_source_pil.size, (0, 0, 0)), image_mask_pil)\n",
    "\n",
    "    result_image.save(out_path)\n",
    "\n",
    "import os\n",
    "folder_path = '/purestorage/project/tyk/9_Animation/Segmentation/Grounded-Segment-Anything/assets/animals'\n",
    "out_folder_path = '/purestorage/project/tyk/9_Animation/Segmentation/Grounded-Segment-Anything/output'\n",
    "\n",
    "\n",
    "print(os.listdir(folder_path))\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if \"강아지\" in file_name:\n",
    "        prompt = 'dog full body including clothes'\n",
    "    elif \"고양이\" in file_name:\n",
    "        prompt = 'cat full body including clothes'\n",
    "    else:\n",
    "        continue\n",
    "    file_name_prefix = file_name.rsplit(\".\", 1)[0]\n",
    "    # print(os.path.join(out_folder_path, f\"{file_name_prefix}.png\"))\n",
    "    do_inference(prompt=prompt, box_threshold=0.3, \n",
    "    text_threshold=0.25, local_image_path=os.path.join(folder_path, file_name), out_path=os.path.join(out_folder_path, f\"{file_name_prefix}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
